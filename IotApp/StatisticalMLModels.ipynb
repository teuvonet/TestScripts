{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ccc2a1e",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96a176fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score, roc_auc_score, accuracy_score, mean_squared_error,\n",
    "                             confusion_matrix, precision_recall_curve, roc_curve, brier_score_loss)\n",
    "\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d771dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/asim/takshshila/IOT/Datasets/setup-stuff/gateway_and_dataset\"\n",
    "result_dir = \"/home/asim/takshshila/IOT/Datasets/setup-stuff/gateway_and_dataset/Results/DT\"\n",
    "datasets = [\"Instant_Liking\"]\n",
    "\n",
    "#x_column_drop = {\"Instant_Liking\": ['q8.2', 'q8.8', 'q8.12', 'q8.20']}\n",
    "\n",
    "x_column_drop = {\"Instant_Liking\": []}\n",
    "\n",
    "target_column = {\"Instant_Liking\": ['Instant.Liking']}\n",
    "\n",
    "seeds = [1, 50, 100, 150, 200, 250, 300, 350, 400, 450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3587087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_pred_tuned(train_path, validation_path, train_column_drop, validation_column, details=None):\n",
    "    \n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_validation = pd.read_csv(validation_path)\n",
    "    \n",
    "    X = df_train.drop(train_column_drop, axis = 1)\n",
    "    y = df_train[validation_column]\n",
    "    \n",
    "    X_validation = df_validation.drop(train_column_drop, axis = 1)\n",
    "    y_validation = df_validation[validation_column]\n",
    "    \n",
    "    # Build models with hyperparameters sets\n",
    "    RSC = RandomizedSearchCV(\n",
    "        estimator=DecisionTreeRegressor(),\n",
    "        param_distributions={\n",
    "            'criterion': ['squared_error'],\n",
    "            'max_depth': range(1, 100, 10),\n",
    "            'max_features': ['auto', 'sqrt', 'log2']}, \n",
    "        cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose = True)\n",
    "    \n",
    "    # Fit RandomizedSearchCV to find best hyperparameters\n",
    "    search_result = RSC.fit(X, y.values.ravel())\n",
    "    print(\"Best using: \", search_result.best_params_, \"Score: \", search_result.best_score_)\n",
    "\n",
    "    # Build models with optimized hyperparameters\n",
    "    model_DT = DecisionTreeRegressor(\n",
    "        criterion=search_result.best_params_[\"criterion\"],\n",
    "        max_depth=search_result.best_params_[\"max_depth\"],\n",
    "        max_features=search_result.best_params_[\"max_features\"])\n",
    "\n",
    "    model_DT.fit(X, y.values.ravel())\n",
    "    train_pred = model_DT.predict(X)\n",
    "    y_pred = model_DT.predict(X_validation)\n",
    "    \n",
    "    train_rmse = mean_squared_error(y, train_pred, squared=False)\n",
    "    \n",
    "    test_rmse = mean_squared_error(y_validation, y_pred, squared=False)\n",
    "\n",
    "    details['training_rmse'] = train_rmse\n",
    "    details['testing_rmse'] = test_rmse\n",
    "\n",
    "    print('Training RMSE: ', train_rmse, 'Testing RMSE: ', test_rmse)\n",
    "\n",
    "    return model_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0089e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_pred_default(train_path, validation_path, train_column_drop, validation_column, details=None):\n",
    "    \n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_validation = pd.read_csv(validation_path)\n",
    "    \n",
    "    \n",
    "    X = df_train.drop(train_column_drop, axis = 1)\n",
    "    y = df_train[validation_column]\n",
    "    \n",
    "   \n",
    "    X_validation = df_validation.drop(train_column_drop, axis = 1)\n",
    "    y_validation = df_validation[validation_column]\n",
    "\n",
    "    # Build models with optimized hyperparameters\n",
    "    model_DT = DecisionTreeRegressor()\n",
    "\n",
    "    model_DT.fit(X, y.values.ravel())\n",
    "    train_pred = model_DT.predict(X)\n",
    "    y_pred = model_DT.predict(X_validation)\n",
    "    \n",
    "    train_rmse = mean_squared_error(y, train_pred, squared=False)\n",
    "    \n",
    "    test_rmse = mean_squared_error(y_validation, y_pred, squared=False)\n",
    "\n",
    "    details['training_rmse'] = train_rmse\n",
    "    details['testing_rmse'] = test_rmse\n",
    "\n",
    "    print('Training RMSE: ', train_rmse, 'Testing RMSE: ', test_rmse)\n",
    "\n",
    "    return model_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7af2d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 2/10 [00:01<00:04,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'max_features': 'auto', 'max_depth': 41, 'criterion': 'squared_error'} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best using:  {'max_features': 'auto', 'max_depth': 41, 'criterion': 'squared_error'} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▌                          | 4/10 [00:01<00:01,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'max_features': 'auto', 'max_depth': 11, 'criterion': 'squared_error'} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best using:  {'max_features': 'auto', 'max_depth': 11, 'criterion': 'squared_error'} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████▍                 | 6/10 [00:01<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'max_features': 'auto', 'max_depth': 91, 'criterion': 'squared_error'} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best using:  {'max_features': 'auto', 'max_depth': 31, 'criterion': 'squared_error'} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████▏        | 8/10 [00:02<00:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'max_features': 'auto', 'max_depth': 41, 'criterion': 'squared_error'} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best using:  {'max_features': 'auto', 'max_depth': 31, 'criterion': 'squared_error'} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:02<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'max_features': 'auto', 'max_depth': 81, 'criterion': 'squared_error'} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best using:  {'max_features': 'auto', 'max_depth': 11, 'criterion': 'squared_error'} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, dataset in enumerate(datasets):\n",
    "    df = pd.DataFrame()\n",
    "    for seed in tqdm(seeds):\n",
    "        csv_path_train = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_train.csv')\n",
    "        csv_path_validation = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_validation.csv')\n",
    "        csv_path_test = os.path.join(data_dir, dataset, \"Test\", dataset + '_Test_seed' + str(seed) + '_modified.csv')\n",
    "        df_test = pd.read_csv(csv_path_test)\n",
    "        \n",
    "        X_test = df_test.drop(x_column_drop[dataset], axis = 1)\n",
    "        y_test = df_test[target_column[dataset]]\n",
    "        \n",
    "#         print(seed)\n",
    "#         print(\"test_\", X_test.columns[X_test.isna().any()].tolist(), X_test.columns)\n",
    "        \n",
    "#         df_train = pd.read_csv(csv_path_train)\n",
    "#         df_val = pd.read_csv(csv_path_validation)\n",
    "        \n",
    "#         #print(seed)\n",
    "#         print(\"train_\", df_train.columns[df_train.isna().any()].tolist(), df_train.columns)\n",
    "#         print(\"val\", df_val.columns[df_val.isna().any()].tolist(), df_val.columns)\n",
    "        \n",
    "        \n",
    "        details = {\n",
    "            'dataset': dataset,\n",
    "            'seed': str(seed)\n",
    "        }\n",
    "        \n",
    "        # For DT\n",
    "        model_DT = DT_pred_tuned(csv_path_train, csv_path_validation, x_column_drop[dataset], target_column[dataset], details)\n",
    "        \n",
    "        importances = model_DT.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        top_k = 10\n",
    "        top_indices = indices[:top_k]\n",
    "        details['best_feature_list'] = np.array(X_test.columns)[indices][0:top_k]\n",
    "        \n",
    "        y_pred = model_DT.predict(X_test)\n",
    "        validation_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        details['validation_rmse'] = validation_rmse\n",
    "        \n",
    "        df = df.append(details, ignore_index=True)\n",
    "        #filepath = Path(dataset + '_DT_tuned.csv')\n",
    "        filepath = Path(result_dir, dataset, \"{}_DT_tuned_.csv\".format(dataset))\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a09df7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instant_Liking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▌                          | 4/10 [00:00<00:00, 33.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 32.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "    df = pd.DataFrame()\n",
    "    print(dataset)\n",
    "    for seed in tqdm(seeds):\n",
    "        csv_path_train = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_train.csv')\n",
    "        csv_path_validation = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_validation.csv')\n",
    "        csv_path_test = os.path.join(data_dir, dataset, \"Test\", dataset + '_Test_seed' + str(seed) + '_modified.csv')\n",
    "        df_test = pd.read_csv(csv_path_test)\n",
    "            \n",
    "        X_test = df_test.drop(x_column_drop[dataset], axis = 1)\n",
    "        y_test = df_test[target_column[dataset]]\n",
    "        \n",
    "        details = {\n",
    "            'dataset': dataset,\n",
    "            'seed': str(seed)\n",
    "        }\n",
    "        \n",
    "        # For DT\n",
    "        model_DT = DT_pred_default(csv_path_train, csv_path_validation, x_column_drop[dataset], target_column[dataset], details)\n",
    "        \n",
    "        importances = model_DT.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        top_k = 10\n",
    "        top_indices = indices[:top_k]\n",
    "        details['best_feature_list'] = np.array(X_test.columns)[indices][0:top_k]\n",
    "        \n",
    "        y_pred = model_DT.predict(X_test)\n",
    "        validation_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        details['validation_rmse'] = validation_rmse\n",
    "        \n",
    "        df = df.append(details, ignore_index=True)\n",
    "        #filepath = Path(dataset + '_DT_default.csv')\n",
    "        filepath = Path(result_dir, dataset,\"{}_DT_default.csv\".format(dataset))\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c446c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb846127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d393b8c",
   "metadata": {},
   "source": [
    "## GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "019f629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score, roc_auc_score, accuracy_score, mean_squared_error,\n",
    "                             confusion_matrix, precision_recall_curve, roc_curve, brier_score_loss)\n",
    "\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1a78120",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/asim/takshshila/IOT/Datasets/setup-stuff/gateway_and_dataset\"\n",
    "result_dir = \"/home/asim/takshshila/IOT/Datasets/setup-stuff/gateway_and_dataset/Results/GB\"\n",
    "datasets = [\"Instant_Liking\"]\n",
    "\n",
    "#x_column_drop = {\"Instant_Liking\": ['q8.2', 'q8.8', 'q8.12', 'q8.20']}\n",
    "x_column_drop = {\"Instant_Liking\": []}\n",
    "\n",
    "target_column = {\"Instant_Liking\": ['Instant.Liking']}\n",
    "\n",
    "seeds = [1, 50, 100, 150, 200, 250, 300, 350, 400, 450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d01d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GB_pred_tuned(train_path, validation_path, train_column_drop, validation_column, details=None):\n",
    "    \n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_validation = pd.read_csv(validation_path)\n",
    "    \n",
    "    X = df_train.drop(train_column_drop, axis = 1)\n",
    "    y = df_train[validation_column]\n",
    "    \n",
    "    X_validation = df_validation.drop(train_column_drop, axis = 1)\n",
    "    y_validation = df_validation[validation_column]\n",
    "    \n",
    "    # Build models with hyperparameters sets\n",
    "    RSC = RandomizedSearchCV(\n",
    "        estimator=GradientBoostingRegressor(loss='squared_error'),\n",
    "        param_distributions={\n",
    "            'n_estimators': range(1, 200, 10),\n",
    "            'max_depth': range(1, 100, 10),\n",
    "            'max_features': ['auto', 'sqrt', 'log2']\n",
    "        },\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit RandomizedSearchCV to find best hyperparameters\n",
    "    search_result = RSC.fit(X, y.values.ravel())\n",
    "    print(\"Best using: \", search_result.best_params_, \"Score: \", search_result.best_score_)\n",
    "\n",
    "    # Build models with optimized hyperparameters\n",
    "    model_GB = GradientBoostingRegressor(\n",
    "        n_estimators=search_result.best_params_[\"n_estimators\"],\n",
    "        max_depth=search_result.best_params_[\"max_depth\"],\n",
    "        max_features=search_result.best_params_[\"max_features\"],\n",
    "        loss='squared_error'\n",
    "    )\n",
    "    \n",
    "    # for train, test in kf.split(X):\n",
    "    model_GB.fit(X, y.values.ravel())\n",
    "    train_pred = model_GB.predict(X)\n",
    "    y_pred = model_GB.predict(X_validation)\n",
    "    \n",
    "    train_rmse = mean_squared_error(y, train_pred, squared=False)\n",
    "    \n",
    "    test_rmse = mean_squared_error(y_validation, y_pred, squared=False)\n",
    "\n",
    "    details['training_rmse'] = train_rmse\n",
    "    details['testing_rmse'] = test_rmse\n",
    "\n",
    "    print('Training RMSE: ', train_rmse, 'Testing RMSE: ', test_rmse)\n",
    "\n",
    "    return model_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37c0c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GB_pred_default(train_path, validation_path, train_column_drop, validation_column, details=None):\n",
    "    \n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_validation = pd.read_csv(validation_path)\n",
    "    \n",
    "    X = df_train.drop(train_column_drop, axis = 1)\n",
    "    y = df_train[validation_column]\n",
    "    \n",
    "    X_validation = df_validation.drop(train_column_drop, axis = 1)\n",
    "    y_validation = df_validation[validation_column]\n",
    "    \n",
    "    model_GB = GradientBoostingRegressor(loss='squared_error')\n",
    "    \n",
    "    # for train, test in kf.split(X):\n",
    "    model_GB.fit(X, y.values.ravel())\n",
    "    train_pred = model_GB.predict(X)\n",
    "    y_pred = model_GB.predict(X_validation)\n",
    "    \n",
    "    train_rmse = mean_squared_error(y, train_pred, squared=False)\n",
    "    \n",
    "    test_rmse = mean_squared_error(y_validation, y_pred, squared=False)\n",
    "\n",
    "    details['training_rmse'] = train_rmse\n",
    "    details['testing_rmse'] = test_rmse\n",
    "\n",
    "    print('Training RMSE: ', train_rmse, 'Testing RMSE: ', test_rmse)\n",
    "\n",
    "    return model_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "231d5e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instant_Liking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:01<00:11,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'n_estimators': 71, 'max_features': 'auto', 'max_depth': 71} Score:  -0.00024405844094009497\n",
      "Training RMSE:  0.00024396746158121584 Testing RMSE:  0.00024001456975285008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 2/10 [00:02<00:08,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'n_estimators': 61, 'max_features': 'auto', 'max_depth': 31} Score:  -0.0007094611373746764\n",
      "Training RMSE:  0.0007094072289094762 Testing RMSE:  0.000691482464993189\n",
      "Best using:  {'n_estimators': 151, 'max_features': 'auto', 'max_depth': 61} Score:  -5.263115722996402e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 3/10 [00:03<00:09,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  5.2617637245807296e-08 Testing RMSE:  5.3999550384404055e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 4/10 [00:05<00:08,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'n_estimators': 71, 'max_features': 'auto', 'max_depth': 31} Score:  -0.000245501488233282\n",
      "Training RMSE:  0.00024547340241273704 Testing RMSE:  0.00024097045625570904\n",
      "Best using:  {'n_estimators': 181, 'max_features': 'auto', 'max_depth': 31} Score:  -1.3541376934642696e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 5/10 [00:06<00:07,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.3536196845100662e-08 Testing RMSE:  1.347536201008617e-08\n",
      "Best using:  {'n_estimators': 181, 'max_features': 'auto', 'max_depth': 51} Score:  -1.46020981190102e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 6/10 [00:08<00:06,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.4874872162667696e-08 Testing RMSE:  1.4917029983470483e-08\n",
      "Best using:  {'n_estimators': 121, 'max_features': 'auto', 'max_depth': 71} Score:  -1.256476471088893e-06\n",
      "Training RMSE:  1.2562288327218208e-06 Testing RMSE:  1.2184833171908293e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▊             | 7/10 [00:10<00:04,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'n_estimators': 171, 'max_features': 'auto', 'max_depth': 41} Score:  -1.4109985774210231e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 8/10 [00:12<00:03,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.3487292515707262e-08 Testing RMSE:  1.3326263378697638e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████▌    | 9/10 [00:13<00:01,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'n_estimators': 121, 'max_features': 'auto', 'max_depth': 81} Score:  -1.2585454373943123e-06\n",
      "Training RMSE:  1.2584740889837721e-06 Testing RMSE:  1.2861361646827227e-06\n",
      "Best using:  {'n_estimators': 191, 'max_features': 'auto', 'max_depth': 81} Score:  -1.3693030400662802e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:15<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.3690412573680062e-08 Testing RMSE:  1.3667214956351285e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For GB tuned\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "    df = pd.DataFrame()\n",
    "    print(dataset)\n",
    "    for seed in tqdm(seeds):\n",
    "        csv_path_train = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_train.csv')\n",
    "        csv_path_validation = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_validation.csv')\n",
    "        csv_path_test = os.path.join(data_dir, dataset, \"Test\", dataset + '_Test_seed' + str(seed) + '_modified.csv')\n",
    "        df_test = pd.read_csv(csv_path_test)\n",
    "        \n",
    "        # print(csv_path_train, csv_path_test)\n",
    "        \n",
    "        X_test = df_test.drop(x_column_drop[dataset], axis = 1)\n",
    "        y_test = df_test[target_column[dataset]]\n",
    "        \n",
    "        details = {\n",
    "            'dataset': dataset,\n",
    "            'seed': str(seed)\n",
    "        }\n",
    "        \n",
    "        # For GB\n",
    "        model_GB = GB_pred_tuned(csv_path_train, csv_path_validation, x_column_drop[dataset], target_column[dataset], details)\n",
    "        \n",
    "        importances = model_GB.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        top_k = 10\n",
    "        top_indices = indices[:top_k]\n",
    "        details['best_feature_list'] = np.array(X_test.columns)[indices][0:top_k]\n",
    "        \n",
    "        y_pred = model_GB.predict(X_test)\n",
    "        validation_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        details['validation_rmse'] = validation_rmse\n",
    "        \n",
    "        df = df.append(details, ignore_index=True)\n",
    "        filepath = Path(dataset + '_GB_tuned.csv')\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2083eca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instant_Liking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:00<00:01,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.1491181419897724e-05 Testing RMSE:  1.1304995127520057e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████▏                              | 3/10 [00:00<00:01,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.1650739120389105e-05 Testing RMSE:  1.1356357079049993e-05\n",
      "Training RMSE:  1.134392537624323e-05 Testing RMSE:  1.1641854365313064e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 4/10 [00:00<00:01,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.1562113171141504e-05 Testing RMSE:  1.1350018611966868e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 5/10 [00:01<00:01,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.1480903293928917e-05 Testing RMSE:  1.1429305435800621e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 6/10 [00:01<00:01,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.1354686497578853e-05 Testing RMSE:  1.138686753814791e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▊             | 7/10 [00:01<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.148090329392493e-05 Testing RMSE:  1.1135940177065398e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 8/10 [00:01<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.1439424344666385e-05 Testing RMSE:  1.1302845357478701e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████▌    | 9/10 [00:02<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.1501423098399319e-05 Testing RMSE:  1.1754231828543837e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:02<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  1.1611703362546328e-05 Testing RMSE:  1.1592027992183146e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For GB default\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "    df = pd.DataFrame()\n",
    "    print(dataset)\n",
    "    for seed in tqdm(seeds):\n",
    "        csv_path_train = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_train.csv')\n",
    "        csv_path_validation = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_validation.csv')\n",
    "        csv_path_test = os.path.join(data_dir, dataset, \"Test\", dataset + '_Test_seed' + str(seed) + '_modified.csv')\n",
    "        df_test = pd.read_csv(csv_path_test)\n",
    "        \n",
    "        # print(csv_path_train, csv_path_test)\n",
    "        \n",
    "        X_test = df_test.drop(x_column_drop[dataset], axis = 1)\n",
    "        y_test = df_test[target_column[dataset]]\n",
    "        \n",
    "        details = {\n",
    "            'dataset': dataset,\n",
    "            'seed': str(seed)\n",
    "        }\n",
    "        \n",
    "        # For GB\n",
    "        model_GB = GB_pred_default(csv_path_train, csv_path_validation, x_column_drop[dataset], target_column[dataset], details)\n",
    "        \n",
    "        importances = model_GB.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        top_k = 10\n",
    "        top_indices = indices[:top_k]\n",
    "        details['best_feature_list'] = np.array(X_test.columns)[indices][0:top_k]\n",
    "        \n",
    "        y_pred = model_GB.predict(X_test)\n",
    "        validation_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        details['validation_rmse'] = validation_rmse\n",
    "        \n",
    "        df = df.append(details, ignore_index=True)\n",
    "        filepath = Path(dataset + '_GB_default.csv')\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a877f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5b947a3",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "369c48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score, roc_auc_score, accuracy_score, mean_squared_error,\n",
    "                             confusion_matrix, precision_recall_curve, roc_curve, brier_score_loss)\n",
    "\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8e0d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/asim/takshshila/IOT/Datasets/setup-stuff/gateway_and_dataset\"\n",
    "result_dir = \"/home/asim/takshshila/IOT/Datasets/setup-stuff/gateway_and_dataset/Results/GB\"\n",
    "datasets = [\"Instant_Liking\"]\n",
    "\n",
    "x_column_drop = {\"Instant_Liking\": []} #'q8.2', 'q8.8', 'q8.12', 'q8.20'\n",
    "\n",
    "target_column = {\"Instant_Liking\": ['Instant.Liking']}\n",
    "\n",
    "seeds = [1, 50, 100, 150, 200, 250, 300, 350, 400, 450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af1cc527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Module -> hyperparameter tuning\n",
    "def RF_pred_tuned(train_path, validation_path, train_column_drop, validation_column, details=None):\n",
    "    \n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_validation = pd.read_csv(validation_path)\n",
    "    \n",
    "    X = df_train.drop(train_column_drop, axis = 1)\n",
    "    y = df_train[validation_column]\n",
    "    \n",
    "    X_validation = df_validation.drop(train_column_drop, axis = 1)\n",
    "    y_validation = df_validation[validation_column]\n",
    "    \n",
    "    # Build models with hyperparameters sets\n",
    "    RSC = RandomizedSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        param_distributions={\n",
    "            'n_estimators': range(1, 200, 10),\n",
    "            'max_depth': range(1, 100, 10),\n",
    "            'max_features': ['auto', 'sqrt', 'log2']}, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "    # Fit RandomizedSearchCV to find best hyperparameters\n",
    "    search_result = RSC.fit(X, y.values.ravel())\n",
    "    print(\"Best using: \", search_result.best_params_, \"Score: \", search_result.best_score_)\n",
    "\n",
    "    # Build models with optimized hyperparameters\n",
    "    model_RF = RandomForestRegressor(\n",
    "        n_estimators=search_result.best_params_[\"n_estimators\"],\n",
    "        max_depth=search_result.best_params_[\"max_depth\"],\n",
    "        max_features=search_result.best_params_[\"max_features\"]\n",
    "    )\n",
    "    \n",
    "    model_RF.fit(X, y.values.ravel())\n",
    "    train_pred = model_RF.predict(X)\n",
    "    y_pred = model_RF.predict(X_validation)\n",
    "    \n",
    "    train_rmse = mean_squared_error(y, train_pred, squared=False)\n",
    "    \n",
    "    test_rmse = mean_squared_error(y_validation, y_pred, squared=False)\n",
    "\n",
    "    details['training_rmse'] = train_rmse\n",
    "    details['testing_rmse'] = test_rmse\n",
    "\n",
    "    print('Training RMSE: ', train_rmse, 'Testing RMSE: ', test_rmse)\n",
    "    \n",
    "    return model_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d85381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Module -> default parameters\n",
    "def RF_pred_default(train_path, validation_path, train_column_drop, validation_column, details=None):\n",
    "    \n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_validation = pd.read_csv(validation_path)\n",
    "    \n",
    "    X = df_train.drop(train_column_drop, axis = 1)\n",
    "    y = df_train[validation_column]\n",
    "    \n",
    "    X_validation = df_validation.drop(train_column_drop, axis = 1)\n",
    "    y_validation = df_validation[validation_column]\n",
    "    \n",
    "    model_RF = RandomForestRegressor()\n",
    "    \n",
    "    model_RF.fit(X, y.values.ravel())\n",
    "    train_pred = model_RF.predict(X)\n",
    "    y_pred = model_RF.predict(X_validation)\n",
    "    \n",
    "    train_rmse = mean_squared_error(y, train_pred, squared=False)\n",
    "    \n",
    "    test_rmse = mean_squared_error(y_validation, y_pred, squared=False)\n",
    "\n",
    "    details['training_rmse'] = train_rmse\n",
    "    details['testing_rmse'] = test_rmse\n",
    "\n",
    "    print('Training RMSE: ', train_rmse, 'Testing RMSE: ', test_rmse)\n",
    "    \n",
    "    return model_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f1a06b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instant_Liking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'n_estimators': 171, 'max_features': 'auto', 'max_depth': 21} Score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▍                                       | 1/10 [00:02<00:26,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Best using:  {'n_estimators': 101, 'max_features': 'auto', 'max_depth': 91} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 2/10 [00:04<00:16,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'n_estimators': 131, 'max_features': 'auto', 'max_depth': 91} Score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 3/10 [00:06<00:14,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 4/10 [00:08<00:11,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'n_estimators': 61, 'max_features': 'auto', 'max_depth': 41} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Best using:  {'n_estimators': 141, 'max_features': 'auto', 'max_depth': 41} Score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 5/10 [00:10<00:10,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Best using:  {'n_estimators': 141, 'max_features': 'auto', 'max_depth': 11} Score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 6/10 [00:12<00:08,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Best using:  {'n_estimators': 191, 'max_features': 'auto', 'max_depth': 71} Score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▊             | 7/10 [00:15<00:07,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 8/10 [00:17<00:04,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'n_estimators': 51, 'max_features': 'auto', 'max_depth': 81} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n",
      "Best using:  {'n_estimators': 101, 'max_features': 'auto', 'max_depth': 91} Score:  0.0\n",
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████▌    | 9/10 [00:19<00:02,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best using:  {'n_estimators': 131, 'max_features': 'auto', 'max_depth': 31} Score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:21<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Driver for tuned RF\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "    df = pd.DataFrame()\n",
    "    print(dataset)\n",
    "    for seed in tqdm(seeds):\n",
    "        csv_path_train = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_train.csv')\n",
    "        csv_path_validation = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_validation.csv')\n",
    "        csv_path_test = os.path.join(data_dir, dataset, \"Test\", dataset + '_Test_seed' + str(seed) + '_modified.csv')\n",
    "        df_test = pd.read_csv(csv_path_test)\n",
    "        \n",
    "        X_test = df_test.drop(x_column_drop[dataset], axis = 1)\n",
    "        y_test = df_test[target_column[dataset]]\n",
    "        \n",
    "        details = {\n",
    "            'dataset': dataset,\n",
    "            'seed': str(seed)\n",
    "        }\n",
    "        \n",
    "        # For RF\n",
    "        model_RF = RF_pred_tuned(csv_path_train, csv_path_validation, x_column_drop[dataset], target_column[dataset], details)\n",
    "        \n",
    "        importances = model_RF.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        top_k = 10\n",
    "        top_indices = indices[:top_k]\n",
    "        details['best_feature_list'] = np.array(X_test.columns)[indices][0:top_k]\n",
    "        \n",
    "        y_pred = model_RF.predict(X_test)\n",
    "        validation_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        details['validation_rmse'] = validation_rmse\n",
    "        \n",
    "        df = df.append(details, ignore_index=True)\n",
    "        filepath = Path(dataset + '_RF_tuned.csv')\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35e15d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instant_Liking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 2/10 [00:00<00:02,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 3/10 [00:00<00:01,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 4/10 [00:01<00:01,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 5/10 [00:01<00:01,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 6/10 [00:01<00:01,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▊             | 7/10 [00:01<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 8/10 [00:02<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████▌    | 9/10 [00:02<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:02<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0 Testing RMSE:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Driver for default RF\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "    df = pd.DataFrame()\n",
    "    print(dataset)\n",
    "    for seed in tqdm(seeds):\n",
    "        csv_path_train = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_train.csv')\n",
    "        csv_path_validation = os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_validation.csv')\n",
    "        csv_path_test = os.path.join(data_dir, dataset, \"Test\", dataset + '_Test_seed' + str(seed) + '_modified.csv')\n",
    "        df_test = pd.read_csv(csv_path_test)\n",
    "        \n",
    "        X_test = df_test.drop(x_column_drop[dataset], axis = 1)\n",
    "        y_test = df_test[target_column[dataset]]\n",
    "        \n",
    "        details = {\n",
    "            'dataset': dataset,\n",
    "            'seed': str(seed)\n",
    "        }\n",
    "        \n",
    "        # For RF\n",
    "        model_RF = RF_pred_default(csv_path_train, csv_path_validation, x_column_drop[dataset], target_column[dataset], details)\n",
    "        \n",
    "        importances = model_RF.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        top_k = 10\n",
    "        top_indices = indices[:top_k]\n",
    "        details['best_feature_list'] = np.array(X_test.columns)[indices][0:top_k]\n",
    "        \n",
    "        y_pred = model_RF.predict(X_test)\n",
    "        validation_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        details['validation_rmse'] = validation_rmse\n",
    "        \n",
    "        df = df.append(details, ignore_index=True)\n",
    "        filepath = Path(dataset + '_RF_default.csv')\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58094381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
